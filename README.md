# DustPedia Data Processing Pipeline

Pipeline to process a set of multiwavelength observations from the DustPedia archieve and prepare a input table for CIGALE. The scripts are the work of a two week summer school (ISM of Galaxies 2021), so please forgive any bugs or mistakes in the code. 

## Set-Up the Pipeline on your Computer

In order to run the pipeline, the following prerequisits are necessary to install:

* Download the `pipeline` folder on your computer.
* **Convolution kernels:** Download the convolution kernels from https://www.astro.princeton.edu/~draine/Kernels/
* **Convolution Script:** In order to apply the kernels from Aniano 2011, download the following script from https://github.com/hsalas/convolution/blob/master/convolve_image.py and store it in the `pipeline` folder.
* **DustPedia Data:** Download the relevant fits files from http://dustpedia.astro.noa.gr/


## How to run the pipeline

TBD

